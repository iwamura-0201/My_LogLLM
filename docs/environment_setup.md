# uvä»®æƒ³ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…å®¹

LogLLMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ã®uvä»®æƒ³ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚

**ä»®æƒ³ç’°å¢ƒãƒ‘ã‚¹**: `/home/siwamura/LogLLM/.venv`

---

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

### ã‚³ã‚¢æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | èª¬æ˜ |
|-----------|---------|------|
| torch | 2.4.0+cu121 | PyTorch (CUDA 12.1å¯¾å¿œ) |
| torchvision | 0.19.0+cu121 | ç”»åƒå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| torchaudio | 2.4.0+cu121 | éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| transformers | 4.46.3 | Hugging Face Transformersï¼ˆBERTã€Llamaå¯¾å¿œï¼‰ |
| datasets | 3.1.0 | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| peft | 0.13.2 | Parameter-Efficient Fine-Tuning (LoRAç­‰) |
| accelerate | 1.0.1 | å­¦ç¿’ã®é«˜é€ŸåŒ–ãƒ»åˆ†æ•£å‡¦ç† |
| bitsandbytes | 0.45.3 | é‡å­åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ4bit/8bitï¼‰ |

### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»è§£æ

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | èª¬æ˜ |
|-----------|---------|------|
| numpy | 1.26.4 | æ•°å€¤è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| pandas | 2.3.3 | ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç† |
| scikit-learn | 1.3.2 | æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆè©•ä¾¡æŒ‡æ¨™ç­‰ï¼‰ |
| scipy | 1.16.3 | ç§‘å­¦è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |

### CUDAé–¢é€£ï¼ˆNVIDIAï¼‰

- nvidia-cublas-cu12==12.1.3.1
- nvidia-cuda-cupti-cu12==12.1.105
- nvidia-cuda-nvrtc-cu12==12.1.105
- nvidia-cuda-runtime-cu12==12.1.105
- nvidia-cudnn-cu12==9.1.0.70
- nvidia-cufft-cu12==11.0.2.54
- nvidia-curand-cu12==10.3.2.106
- nvidia-cusolver-cu12==11.4.5.107
- nvidia-cusparse-cu12==12.1.0.106
- nvidia-nccl-cu12==2.20.5
- nvidia-nvjitlink-cu12==12.9.86
- nvidia-nvtx-cu12==12.1.105
- triton==3.0.0

### ãã®ä»–ã®ä¾å­˜é–¢ä¿‚

åˆè¨ˆ68ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

## ä»®æƒ³ç’°å¢ƒã®ä½¿ç”¨æ–¹æ³•

### 1. ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–

```bash
cd /home/siwamura/LogLLM
source .venv/bin/activate
```

### 2. æœ‰åŠ¹åŒ–ã®ç¢ºèª

ä»®æƒ³ç’°å¢ƒãŒæœ‰åŠ¹åŒ–ã•ã‚Œã‚‹ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«`(.venv)`ãŒè¡¨ç¤ºã•ã‚Œã¾ã™:

```
(.venv) user@host:~/LogLLM$
```

### 3. Pythonã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª

```bash
# Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
python --version

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸€è¦§
uv pip list

# ç‰¹å®šãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
```

### 4. ä»®æƒ³ç’°å¢ƒã®ç„¡åŠ¹åŒ–

```bash
deactivate
```

---

## å­¦ç¿’ãƒ»è©•ä¾¡ã®å®Ÿè¡Œ

ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã—ãŸçŠ¶æ…‹ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã§ãã¾ã™:

### ãƒ‡ãƒ¼ã‚¿æº–å‚™

```bash
# Fixed Size Windowæ–¹å¼
python prepareData/sliding_window.py

# ã¾ãŸã¯ Session Windowæ–¹å¼
python prepareData/session_window.py
```

### ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

```bash
python train.py
```

### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

```bash
python eval.py
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### CUDA ãŒåˆ©ç”¨ã§ããªã„å ´åˆ

```bash
# CUDAåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
python -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('CUDA version:', torch.version.cuda)"
```

CUDA 12.1ãŒå¿…è¦ã§ã™ã€‚ç•°ãªã‚‹CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å ´åˆã¯ã€PyTorchã‚’å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
source .venv/bin/activate
uv pip install <package-name>
```

### ä»®æƒ³ç’°å¢ƒã®å†ä½œæˆ

```bash
rm -rf .venv
uv venv
source .venv/bin/activate
# ä¾å­˜é–¢ä¿‚ã‚’å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```

---

## ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

- **Python**: 3.8ä»¥ä¸Šï¼ˆç¾åœ¨ã®ä»®æƒ³ç’°å¢ƒ: 3.11.13ï¼‰
- **CUDA**: 12.1
- **GPU**: NVIDIA GPUæ¨å¥¨ï¼ˆ16GB VRAMä»¥ä¸Šï¼‰
- **OS**: Linux (Ubuntuç­‰)

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. âœ… ä»®æƒ³ç’°å¢ƒã®æ§‹ç¯‰å®Œäº†
2. ğŸ“ æ¬¡: [adaptation_guide.md](file:///home/siwamura/.gemini/antigravity/brain/b19a3ba4-9eb4-41ef-b529-0a041aa383e1/adaptation_guide.md)ã‚’å‚ç…§ã—ã¦ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚’é–‹å§‹
3. ğŸš€ è‡ªå‰ã®ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
